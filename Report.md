## Web LAb1

### Part 1
#### Section 1 分词
我是用了两种现成的分词工具，并自己加入了一些分词优化以使得分词的结果更符合后续实验要求。两种的现成的分词工具分别为jieba分词和pkuseg分词。
#### Section 2

通过上一阶段生成的分词结果，生成倒排索引表，处理过程中采用{(word，[id1, id2...])...}的格式存储。

首先通过基础方式存储，即对于词典，采取[88byte词项，4byte频率，4byte倒排索引指针]方式顺序存储（发现上述分词结果中最长的词项为85bytes，所以采用88bytes存储，空位使用b'\x00'填充）。

对于倒排索引文件，采用4字节每文档id的方法顺序存储。

（上述生成倒排索引表和词典文件的方法在"web-lab1\src_yzy\inverted_index_gen.py"中，采用基本顺序存储的读取方法测试（从二进制文件还原倒排索引表）包含在"web-lab1\src_yzy\test_basic.py"中）



实际上除了个别长词之外，一般的词项远远达不到88字节，我们考虑对词典文件进行压缩。除去基本存储方法以以外，试图采用单一字符串词典以及按块存储方法，并比较这三种方法的空间占用以及检索效率。

单一字符串方法采用：开头存储二进制长字符串字节数，然后存放对应大小的字符串，接下来每12字节中依次存放{4字节字符串指针，4字节词项频率，4字节倒排索引表指针}

按块存储采用：开头存放字符串方法相同，然后每5项存放一次字符串指针，接着对于每一项的9字节：{1字节词项字符串长度，4字节频率，4字节倒排索引表指针}

相关的存放代码以及读取方式在如下文件中实现：

"web-lab1\src_yzy\word_compress_store_single.py"

"web-lab1\src_yzy\word_compress_store_block.py"

"web-lab1\src_yzy\test_single.py"

"web-lab1\src_yzy\test_block.py"

关于空间占用，结果如下：

（首先在第一阶段中，我们对于book和movie使用两种工具进行了分词，以下是共四组倒排索引表使用三种词典压缩方法后的空间占用对比，相应的倒排索引表文件大小也包括在内，由于对倒排索引表没有压缩因此大小不存在变动）

<table>
  <thead>
    <tr>
      <th></th>
      <th>book_jieba</th>
      <th>book_pkuseg</th>
      <th>movie_jieba</th>
      <th>movie_pkuseg</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>顺序存储</td>
      <td>1836KB</td>
      <td>1844KB</td>
      <td>4958KB</td>
      <td>5780KB</td>
    </tr>
    <tr>
      <td>单一字符串</td>
      <td>355KB</td>
      <td>363KB</td>
      <td>984KB</td>
      <td>1230KB</td>
    </tr>
    <tr>
      <td>按块存储</td>
      <td>313KB</td>
      <td>320KB</td>
      <td>870KB</td>
      <td>1098KB</td>
    </tr>
    <tr>
      <td>倒排索引表</td>
      <td>1180KB</td>
      <td>1184KB</td>
      <td>4817KB</td>
      <td>4512KB</td>
    </tr>
  </tbody>
</table>

从上面的结果可以看出，从简单的顺序存储（每一项使用88字节保证存储超长词汇）到单一字符串的改进大大缩小了词典文件的存储，可见大量的短字符串是达不到88字节的长度的。

从单一字符串到按块索引的改进进一步缩小了词典文件的大小（在这里设置每5个块放置一次字符串指针），理论上除了开始的长字符串可以每60字节节省12字节，实际的表现也非常符合预期结果。

#### Section 3
### Part 2